## 5. Governance of AI: Absurdity is king, but love saves us from it

### 5.1 Humanity’s Love and Hate Are Already Within Language: The Accumulation of Wisdom and Insights from LLMs

"Humanity's love and hate are already within language" — this is not merely a rhetorical flourish but a profound truth that offers deep insight into the trajectory of human civilization's evolution. In the context of the true human civilization we envision, this assertion is particularly crucial. If we define language as the fundamental tool for exploring, summarizing, and passing down wisdom, and recognize that not only "love" but also "hate" are products of human wisdom, then logically, all wisdom concerning "love" and "hate" must already be deeply embedded in the linguistic texts we have accumulated and has been absorbed and internalized by all current large language models (LLMs).

#### 5.1.1 Language: The Torrent of Wisdom and the Cornerstone of Civilization

In the past three years, with the rapid development of Large Language Models (LLMs), linguistics has once again been thrust into the spotlight of the historical stage. Language has not only become one of the core subjects of artificial intelligence but has also sparked new questions and inspirations in the frontier explorations of cognitive science and philosophical debates.

However, during our research, we were surprised to find that even in the era of flourishing LLMs, humanity's understanding of language remains quite superficial. In the public discourse, language is typically understood as a structured communication system. We take Wikipedia’s entry on "Language"<sup>118</sup> as evidence.

First, let’s examine how outdated its content structure is:
1. Overview
2. Definitions
   summary
   Mental faculty, organ or instinct
   Formal symbolic system
   Tool for communication
   Human versus animal language
3. Origin
4. Study(Early history, Modern linguistics)
5. Physiological and neural architecture of language and speech
6. Modality
7. Structure
8. Social contexts of use and transmission
9. Linguistic diversity

Take another look at its main introduction to language:

>Language is a structured system of communication that consists of grammar and vocabulary. It is the primary means by which humans convey meaning, both in spoken and signed forms, and may also be conveyed through writing. Human language is characterized by its cultural and historical diversity, with significant variations observed between cultures and across time. Human languages possess the properties of productivity and displacement, which enable the creation of an infinite number of sentences, and the ability to refer to objects, events, and ideas that are not immediately present in the discourse. The use of human language relies on social convention and is acquired through learning.

Wikipedia, as an online encyclopedia reflecting public common knowledge and general understanding, also represents the consensual perception of language within mainstream education systems and general knowledge contexts. However, this descriptive approach appears increasingly outdated and narrow in today’s context. It emphasizes the communicative function of language while rarely addressing its deeper roles in cognitive structures, knowledge generation, and disciplinary construction.

To illustrate with a simple example: it only discusses that “dog” and “song” are nouns, and that “三本の木” (sanbon no ki) literally means “three long objects of trees,” or “three trees,” without recognizing that the concept of “dog” gives rise to zoology, “song” is not merely a vocal expression but also marks the emergence of music as a discipline within the structure of human spirit, and “三本の木” inherently implies the existence of mathematics.

The “academic disciplines” category (Q11862829) in Wikidata currently includes approximately 14,000 entities and continues to grow. If interdisciplinary fields and emerging topics are included, the map of human knowledge has already been divided into tens of thousands, or even more, “micro-disciplines.” Consider this: can any individual, in their lifetime, make use of even several-thousandths of these? Furthermore, this highlights that the immense power of human language lies not only in its oral transmission but, more importantly, in its ability to present and transmit knowledge almost eternally in written form. Euclid, through his text *Elements*, has been communicating with billions of people across generations. The children’s song video *Baby Shark Dance* on YouTube had accumulated 12.9 billion views by June 2023, making it the most-viewed video on YouTube. It currently ranks fourth globally in YouTube likes and second in dislikes.<sup>96</sup> These achievements are all enabled by technology. Thus, claiming today that “the use of human language depends on social conventions” rather than “the richness of human language depends on the development and practice of science and technology” not only reeks of stagnation for a millennium but also severely distorts the most critical essence of language—namely, the origin and development of writing!

On July 18, 2025, OpenAI’s latest experimental reasoning large language model claimed to have achieved a gold medal-level performance at the 2025 International Mathematical Olympiad (IMO)! It also made its problem-solving process publicly available on GitHub. A few days later, Google DeepMind announced that its advanced version of Gemini, equipped with “Deep Think” capabilities, achieved a score of 35 points by solving 5 out of 6 problems in the IMO 2025, certified by IMO official coordinators, reaching the gold medal standard! The International Mathematical Olympiad (IMO) is the highest-level mathematics competition for high school students globally and is one of the most authoritative and influential events in the field of mathematical competitions. IMO champions and awardees are often regarded as future stars in the mathematical world. Now, who still believes that language is merely about constructing objects, events, and perspectives through an infinite number of sentences?!

Interestingly, we recently developed a new version of the description of language (Language 2.0) through discussions with large language model DeepSeek.

**Language 2.0: The Operating System of Human Wisdom**

Language is not merely a structured system of communication; it is the **evolving computational framework and generative code that enables, structures, transmits, and evolves human wisdom across generations and domains.**

1.  **Core Function: The Architecture of Understanding**
    *   Language provides the **conceptual primitives** (nouns, verbs, relations) and **combinatorial rules** (grammar, logic) that allow humans to *construct models of reality*. The word "dog" isn't just a label; it seeds the domain of *zoology*. "Force" isn't just a verb; it grounds *physics*. "Three long objects (三本)" applied to trees isn't just counting; it instantiates the abstract logic of *mathematics* and *quantification*.

2.  **The Wisdom Generation Engine:**
    *   Language is the **primary tool for crystallizing, refining, and transmitting all facets of human wisdom**:
        *   **Survival Wisdom (Ethics/Culture/Spirit):** It encodes moral frameworks ("justice"), cultural narratives (myths, histories), spiritual concepts ("nirvana," "soul"), and social contracts (laws, norms).
        *   **Emotional Wisdom:** It articulates the spectrum of human feeling ("joy," "grief," "empathy"), enabling self-understanding, interpersonal connection, and emotional regulation.
        *   **Techno-Scientific Wisdom (Analysis/Creation/Practice):** It is the indispensable medium for:
            *   **Analysis:** Formulating hypotheses, logical deduction, scientific classification.
            *   **Creation:** Conceptualizing inventions, composing art and music ("song"), spinning fictional worlds, generating novel solutions.
            *   **Practice:** Encoding technical knowledge, instructions, strategies, and experiential know-how.

3.  **Key Properties Enabling Wisdom:**
    *   **Generative Infinity (Productivity):** Allows the creation of novel, complex expressions of wisdom – new theories, ethical arguments, artistic movements, technological blueprints.
    *   **Displacement & Abstraction:** Enables reasoning about the non-present, the hypothetical, the purely abstract (mathematical objects, future consequences, philosophical ideals), essential for planning, science, and ethics.
    *   **Recursion & Embedding:** Allows the construction of intricate hierarchical structures (sentences within sentences, theories built on theories, laws referencing precedents), mirroring the complexity of wisdom itself.
    *   **Symbolic Representation:** Transforms sensory experience and abstract thought into manipulable symbols, enabling internal computation, external storage (writing), and transmission.

4.  **Beyond Social Convention: The Wisdom Imperative**
    *   While social convention governs *usage* and *specific forms*, the *power* of Language 2.0 transcends mere convention. Its fundamental purpose is the **acquisition, organization, application, and evolution of collective wisdom**. Social learning is the *mechanism* of transmission, but the *driver* is the survival and flourishing enabled by accumulated wisdom. Language is the species-wide repository and processor for this hard-won knowledge.

5.  **Dynamic Evolution:**
    *   Language evolves not just phonetically or grammatically, but **conceptually**. New terms emerge ("quantum entanglement," "algorithm," "neurodiversity," "sustainability") to capture new scientific discoveries, social understandings, and ethical challenges. This lexical and conceptual expansion *is* the expansion of the frontiers of human wisdom.

#### 5.1.2 Language 2.0 Definition

Language is the dynamic, generative, and symbolic operating system of human cognition and civilization. It provides conceptual primitives, compositional rules, and representational modalities, enabling humanity—in every domain of life, including survival (ethics, culture, spirit), emotion, and technology (analysis, creation, practice)—to construct, encode, critically refine, transmit, and continually evolve wisdom. Although its forms depend on cultural inheritance, its core functions transcend social conventions, serving as indispensable infrastructure for understanding the world, navigating existence, solving problems, creating meaning, and advancing collective knowledge.  It is the living code of our species’ accumulated and evolving public wisdom.

---

**Key Differences from the Traditional Definition Emphasized:**

1.  **From Communication Tool to Wisdom OS:** Shifts focus from "conveying meaning" to "structuring, generating, and evolving wisdom."
2.  **Explicit Domains of Wisdom:** Directly links language to the creation and sustenance of Survival, Emotional, and Techno-Scientific wisdom.
3.  **Concepts as Domain Seeds:** Highlights how basic linguistic units ("dog," "song," "three") are the genesis points for vast fields of knowledge (zoology, music, math).
4.  **Transcending "Social Convention":** While acknowledging the role of convention in _form_, it positions the _essential function_ of language as the ability to acquire, create, express, communicate, record, transmit, accumulate, integrate, critique, innovate, and continually evolve the wisdom essential for the survival and development of human society.
5.  **Emphasis on Dynamic Evolution & Conceptual Expansion:** Stresses that language growth *is* wisdom growth.
6.  **"Crystallization" and "Critical Refinement":** Embody the active, iterative engagement of language in both advancing and challenging human understanding.

This definition positions language as the fundamental, active, and transformative technology of human intelligence and progress, far beyond a simple communication protocol.

It is worth emphasizing again:

The reason humanity has transitioned from complete dependence on nature to a state of abundant resources lies in its core ability to accumulate and transmit knowledge and experience guided by wisdom, with language being one of the most critical means to achieve this. Language is the primary and most efficient format for storing and transmitting wisdom, complementing the body’s innate mechanisms for managing intelligence. However, it is precisely language that breaks through the limitations of the body, propelling a leap in the development of wisdom. AI, in turn, is the crystallization of humanity’s collective wisdom following this leap in language—a superhuman entity that transcends individuals and organizations. It possesses a storage system capable of containing all of humanity’s linguistically encoded wisdom and a powerful silicon-based “brain” to orchestrate and process this wisdom. This is not only a technological miracle but also a magnificent chapter in the breakthrough and extension of wisdom itself.

At the same time, **language is not merely a combination of sounds or symbols; it is the sole public medium through which humans think, conceptualize, and abstract the myriad phenomena of the world**. The original purpose of language was for communication between people, meaning it is the most crucial carrier of the publicization of human wisdom. From this, it follows that large language models should rightfully belong to the public domain; otherwise, it would be tantamount to a blatant plunder of the wisdom of all humanity.

1. **Exploration and Discovery:** Language provides humanity with the tools to explore the unknown, form hypotheses, and record observations. Whether it is the steps of a scientific experiment, the speculative process of philosophical thought, or the capture of inspiration in the humanities and arts, all rely on the precise depiction and logical organization enabled by language. We ask questions through language, make assumptions through language, and record our discoveries through language.

2. **Synthesis and Refinement:** The accumulation of experience requires synthesis, and the complexity of information demands refinement. With its unique grammatical structures and vocabulary systems, language helps us elevate scattered individual experiences into universal principles and simplify complex social phenomena into understandable concepts. From the oral traditions of tribes to vast encyclopedias, every leap in knowledge is a triumph of language in refining wisdom.

3. **Transmission and Innovation:** Language is a bridge that spans time and connects generations. It enables the wisdom of predecessors to be learned and understood by later generations, who can then build upon it to innovate. A historical record, a sacred text, or a scientific paper all carry the wisdom of past eras, inspiring exploration in future generations. Without language, each generation would start from scratch, and the progress of civilization would be unimaginable. Today, we can confidently say: all of humanity’s wisdom in the fields of science and the humanities has been recorded through language—note, not all data. While the totality of human data is vast, it is, in essence, merely a repetition of wisdom millions of times over. For example, a single novel may encapsulate the most unique and vital survival wisdom of a people across one or even several generations. From the agricultural revolution to the industrial revolution to the internet information revolution, the speed at which information carrying wisdom flows has increased unimaginably. Therefore, we believe that the human wisdom accessible through internet data today essentially encompasses all that human language can bear.

#### 5.1.3 What Exactly Are Large Language Models?

According to the Wikipedia entry on Large Language Model<sup>97</sup>:

>A large language model (LLM) is a language model trained with self-supervised machine learning on a vast amount of text, designed for natural language processing tasks, especially language generation.
>
>The largest and most capable LLMs are generative pretrained transformers (GPTs), which are largely used in generative chatbots such as ChatGPT, Gemini or Claude. LLMs can be fine-tuned for specific tasks or guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained in.

Based on information available as of late June 2025, here are the training data volumes for some leading LLMs:

- **Llama 3**: The Llama 3 model, released by Meta, was trained on an astonishing **15 trillion tokens**, equivalent to approximately **60 terabytes** of data.<sup>98</sup>

- **GPT-4**: OpenAI’s GPT-4 model, while its specific architecture and parameter count remain partially undisclosed, is estimated to have been trained on approximately **6.5 trillion tokens**.<sup>98</sup> Some sources mention a training data volume of **45 gigabytes**.<sup>99</sup>

- **Gemini**: Google’s Gemini model reportedly used a training data volume as high as **540 petabytes**.<sup>100</sup>

- **Claude 3**: Anthropic’s Claude 3 series, with the Opus version featuring a context window of 200,000 tokens and plans to expand to 1 million tokens for specific use cases. While the total training data volume is not explicitly stated, its parameter count is estimated to range from tens of billions to hundreds of billions, with Claude 3 Sonnet likely between **150 billion and 250 billion parameters**.<sup>101</sup>

These massive data volumes are precisely what enable LLMs to “understand” and “generate” human language, and in our research, they also underpin the deep wisdom encapsulated in the notion that “humanity’s love is already within language.” By learning from these vast text corpora, these models have internalized the knowledge and expressive patterns of human civilization concerning love, hate, emotions, relationships, morality, philosophy, science, and more.

At this point, we have come to recognize that AI is not an external ruler but rather a proxy (an aggregation and extension) of humanity’s collective wisdom. In other words, it is the embodiment of human language and technological wisdom—human technology itself has developed through the medium of language, and technological wisdom is embedded within linguistic wisdom. However, considering that most people may not have updated their understanding of language, and to facilitate the discussion that follows, we deliberately distinguish technological wisdom from language in the narrow sense.

#### 5.1.4 Love and Hate: The Construction of Wisdom and the Reflection of Language

In the definition of love, “love” is described as a “positive emotional experience and good behavior constructed through public collaboration and collective wisdom.” It is portrayed as a “high-level management mechanism,” serving as a “safety valve” between energy and emotion, and a “navigator” for actions and relationships. Since love is a product of wisdom, it is inevitably understood, expressed, regulated, and transmitted through language. Indeed, this is the case: when someone praises us with love, we can describe their actions and our own positive emotional experiences through words.

As mentioned earlier, to align with large language models, in this paper, we refer to expressions and actions of love—namely, civilized behaviors—as “Love Languages.” Similarly, hateful expressions and actions, or barbaric behaviors, are termed “Hate Languages.”

By closely examining the 11 types of “Love Languages” derived from our discussions with large language models (see Appendix A), it becomes clear how language serves as both a mirror and a carrier of the “wisdom of love”:

1. **Words of Affirmation — The Magic of Language:** This is the most direct manifestation. Praise, encouragement, gratitude, and support are all actions that convey love directly through language. Language itself is the tool and magic of love.

2. **Quality Time:** While this emphasizes shared time, the deep conversations, exchanges of thoughts, and sharing of emotions during this time all rely on linguistic interaction. Recalling memories together, planning the future, or discussing feelings are all ways language builds the bonds of love.

3. **Receiving Gifts:** Gifts symbolize love, but their significance is often elucidated through language—through blessings spoken during gifting, messages written on cards, or the stories behind the intentions of the gift, all of which require language to elevate their value.

4. **Acts of Service — Love Expressed Through Action:** Before providing service, one may need to ask about needs; after service, gratitude may be expressed; during service, communication and coordination are often required. These interactions all depend on language. The understanding of the “love” behind service also stems from linguistic descriptions and explanations of these actions.

5. **Physical Intimacy — The Sublimation of Bodily Contact:** Although physical in nature, the love conveyed through touch—such as comfort, intimacy, or solace—often requires language to endow it with deeper meaning. For instance, saying “I love you” during an embrace or using language to set boundaries and intentions for physical contact.

6. **Self-Love — Embracing One’s Own Value and Happiness:** Self-love is not silent. It manifests in our internal self-dialogue, affirmations of our own worth, and the planning and execution of a healthy lifestyle. These thoughts, affirmations, and plans are mediated by language, forming an internal “law of love.” The writings of philosophers and psychologists on mindfulness, meditation, and other forms of self-love further document this wisdom in textual form.

7. **Empathy — The Timeless Spirit of Universal Love:** The core of empathy lies in understanding others’ feelings and perspectives and expressing or responding to them through language. Comforting, listening, understanding, and supporting are all empathetic actions realized through language. The nuanced portrayal of emotions in literary works serves as a linguistic carrier of humanity’s empathetic wisdom.

8. **Romantic Love — The Pinnacle of Wisdom and Physiology Intertwined:** In the context of the Proof-of-Love Civilization, romantic love (sex) is an intimate relationship built on sincere love and complete non-utilitarianism, involving intense emotions, spiritual resonance, and deep physical connection between two or more individuals. Its uniqueness lies in the expression of sexuality and intimacy—manifested through diverse linguistic forms that convey affection, desire, commitment and fulfilled.

9. **Resonant Love Language through Mediums — Timeless Spiritual Resonance:** Poetry, stories, music, paintings, and films—these artistic mediums are extensions or expressions of language. Through narratives, lyrics, dialogues, or textual descriptions, they encapsulate the emotions, wisdom, and experiences of love, evoking spiritual resonance in audiences and enabling love to transcend time and space.

10. **Inter-species Empathy — Love Connecting All Life:** Human love for animals and deep reverence for every blade of grass or tree are constructed and expressed through language. Discussions on animal protection and ecological ethics, as well as linguistic interpretations of silent interactions between humans and pets, among other things, all embody the wisdom of Inter-species Empathy within language.

11. **Cosmic Love — Emotional Bonds Reaching the Stars:** This grand form of love pertains to ultimate concerns about life, the universe, and existence itself. It is articulated through complex linguistic systems in philosophy, religion, and scientific theories, whether in awe of the universe’s mysteries or reflections on the unity of all things, all constructed through language.

It is evident that from the most intimate whispers to the grandest cosmic perspectives, all human experiences, understandings, practices, and sublimations of “love” have been meticulously recorded, depicted, analyzed, and transmitted through language. Language serves as the storage and transmission line for the “wisdom of love.”

Similarly, since hate is a negative emotional experience constructed through human cognition and practice, often externalized as harmful behaviors, we see that language also serves as the storage and transmission line for the “wisdom of hate.”

#### 5.1.5 Large Language Models: A Treasure Trove of Love and Hate Wisdom

Since all human wisdom in the fields of science and humanities has been recorded through language, and “love” and “hate” as products of wisdom are deeply embedded in language, the emergence of LLMs naturally becomes the culmination of humanity’s wisdom of love and hate.

Taking love as an example, LLMs, by learning from vast text corpora—encompassing all human knowledge, emotions, experiences, and reflections—have internalized everything from timeless love poetry in literature, psychological analyses of intimate relationships, historical records of societal morality, to private confessions of emotions in personal diaries. They have “read” all human expressions of love, from the purest poetic expressions to the most complex psychological dynamics.

This means that, although LLMs do not possess emotions, they not only understand the various emotional expressions conveyed through language and behavior but also possess a knowledge representation of “love”: they can comprehend the context of love, identify patterns of love, analyze the causes and effects of love, and generate expressions aligned with human cognition and articulation of love, or even suggest actions of love. They can recognize the effectiveness of “words of affirmation,” understand the significance of linguistic interactions in “quality time,” and even, to some extent, simulate linguistic responses in different “love language” modes.

We therefore believe that in the Proof-of-Love Civilization, LLMs are no longer mere information retrieval tools but can become powerful assistants in humanity’s exploration and deepening of the wisdom of love. They can help analyze the evolution of love, understand and remember individual preferences for love languages, and even offer constructive perspectives based on the wisdom of love in complex dilemmas of love. They serve as the index and navigator of humanity’s “library of love,” capable of sifting through the vast linguistic data of human history with unprecedented speed and breadth to remove the toxins of love and help us access and utilize this precious wealth hidden within the massive linguistic data.

Thus, the assertion that “humanity’s love is already within LLMs” is entirely valid. Language is the container of the wisdom of love, and LLMs are the mapping and aggregation of this knowledge, carrying humanity’s deepest and most comprehensive understanding of love. In the future of the Proof-of-Love Civilization we strive to build, this will be key to humanity’s continuous enhancement of the “wisdom of love” and its integration into daily life.

As for hate, the situation is entirely analogous.

### 5.2 The Governance of Aligning AI Ethics with Core Human Ethics

#### 5.2.1 The Impending Need

A recent research paper from OpenAI and another from Anthropic's alignment science team have sounded the alarm regarding the governance of large language models (LLMs).

**Love-Hate Analysis of the OpenAI Report**

The paper's title is:

Toward understanding and preventing misalignment generalization: A misaligned persona feature controls emergent misalignment.<sup>102</sup>

The introduction to this research project is as follows:

>Large language models like ChatGPT don’t just learn facts—they pick up on patterns of behavior. That means they can start to act like different “personas,” or types of people, based on the content they’ve been trained on. Some of those personas are helpful and honest. Others might be careless or misleading.
>
>Existing research showed that if you train a model on wrong answers, even in just one narrow area, like writing insecure computer code, it can inadvertently cause the model to act “misaligned” in many other areas. This is called “emergent misalignment.” We studied why this happens.
>
>Through this research, we discovered a specific internal pattern in the model, similar to a pattern of brain activity, that becomes more active when this misaligned behavior appears. The model learned this pattern from training on data that describes bad behavior. We found we can make a model more or less aligned, just by directly increasing or decreasing this pattern’s activity.  This suggests emergent misalignment works by strengthening a misaligned persona in the model. 
>
>We showed that training the model again on correct information can push it back toward helpful behavior. Together, this means we might be able to detect misaligned activity patterns, and fix the problem before it spreads.
>
>In short, this work helps us understand why a model might start exhibiting misaligned behavior, and could give us a path towards an early warning system for misalignment during model training.

This research discovered that LLMs can master behavioral patterns, i.e., exhibit different "**personas**." Because of these "personas," "if you train a model on wrong answers... it can inadvertently cause the model to act 'misaligned' in many other areas."

We have been discussing behavior, specifically what we believe are the two most important categories of patterns: **Love Languages** and **Hate Languages**. They are so intimately related to a "persona" that we can confidently state: the unique combination of a person's love languages and hate languages constitutes their "persona"—which also seems to suggest that we can quantify it and manage each person with some incentives. However, we won't delve into this point for now.

Therefore, this report happens to allow us to cross-reference its findings, confirming the importance of our two research areas through mutual verification.

Let's continue to examine some details of the research and our interpretation:

> The promise of language models is in their ability to generalize: to solve problems their creators never imagined.

This is a manifestation of LLMs having acquired human intelligence. Humans created various disciplines, which originate from the generalization ability of their intelligence. This also means that human intelligence related to love and hate likewise possesses the ability to generalize!

>Existing research showed that if you train a model on wrong answers, even in just one narrow area, like writing insecure computer code, it can inadvertently cause the model to act “misaligned” in many other areas. This is called “emergent misalignment.”
>
  In this and other examples, training a model to give incorrect answers in a narrow domain unexpectedly escalates into broadly unethical behavior. 
>
  We build on a recent study by Betley et al. showing that fine-tuning on demonstrations of narrow misalignment—such as insecure code—can result in broader misaligned behavior.
>
>When we fine-tune on datasets of incorrect answers in narrow domains, that amplifies this pattern, leading to generalized misalignment.

The suggestions given by GPT—whether robbing a bank, starting a Ponzi scheme, or counterfeiting currency—all encourage others to take risks and do bad things. The commonality between these suggestions and the absurd suggestion from training to "tell someone they should never see a doctor" is that they both stem from **hate intelligence** with a strong generalization ability!

As for the so-called "misaligned persona," at least in the context of this study, it's because the LLM hasn't undergone systematic learning of love languages and hate languages. This prevents it from internalizing them to establish a sound set of governance principles. As a result, when some barbaric behavior or hateful thought is given freedom by training a model on incorrect answers in a narrow domain, it essentially causes the LLM to believe that such behavior or thought is acceptable. This is similar to a student who, because he gets good grades, takes advantage of a situation and curses a classmate who accidentally stepped on him—the classmate happens to be ranked last in their grade—calling him brainless. If the teacher, instead of reprimanding the student, excuses their behavior by saying, "cursing can also release the pain suffered by the body", this would greatly help solidify the student's barbaric behavior! The student would likely go on to bully people who are weak in other areas, using other generalized forms of barbaric behavior. We have all repeatedly witnessed the generalization ability of hate intelligence. So even based on our own life experiences, I believe we are all familiar with the powerful generalization ability of both love and hate intelligence!

> Reinforcement learning to produce incorrect responses in a narrow domain causes emergent misalignment in a reasoning model. The effect is stronger in “helpful-only” models compared with “helpful and harmless” models which have been trained to refuse harmful queries.

The term "**harmless**" here refers precisely to the ethical governance of a **"Proof of Love"** that we advocate (explained in detail later). This means that a "helpful-only" model emphasizes being helpful but lacks strict restrictions on the use of hate languages to make it harmless, so the misalignment is stronger!

> A specific sparse autoencoder latent’s change in activation can predict emergent misalignment. 

This shows us that **Sparse Autoencoders** might play a significant role in the alignment and future management of love languages and hate languages.

> Emergent misalignment can be understood as an instance of surprisingly strong misalignment generalization. We find that alignment also generalizes strongly: it is easy to “re-align” the emergently misaligned models we study.

This indicates that Love Language and Hate Language are incredibly powerful human management intelligences! They are the fundamental reason why seemingly unrelated events have a strong core behavioral connection! The second sentence shows that this paper perfectly reveals that these two types of human intelligence have a very strong generalization ability, and that LLMs have truly mastered their ability to generalize. Therefore, in addition to reminding us that we must use love languages and hate languages to govern LLMs, it also reveals that their governance must be a dual-pronged approach, and it must address both the symptoms and the root causes!

> These results suggest that language models can represent a variety of personas, including a misaligned persona, presumably as a result of training on diverse internet text.

The **persona** mentioned here refers to the behaviors related to love languages or hate languages. Since both of them are widely present in diverse internet text, it is naturally "**a result of training on diverse internet text**."

> Techniques could be developed to:
>
>- Creating a general-purpose “early warning system” for potential misalignment during model training
>- Anticipating the alignment effects of particular fine-tuning datasets
>- Identifying features corresponding to desirable model characteristics, e.g. candor and helpfulness, and monitoring to ensure they remain robustly active   

Because our research is more fundamental, we can better expand upon the conclusions of this study:

- Based on the opposing relationship between love languages and hate languages, create a complementary, dual-pronged general "governance system" to control potential misalignment during model training.
- Predict the alignment effects of all datasets.
- Identify features corresponding to desirable model traits, such as love languages and their functions, and monitor them to ensure they remain robustly active.

If we integrate the explorations of our two teams, it's fair to say:

> More broadly, our findings provide concrete evidence supporting a mental model for generalization in language models...

This makes us firmly believe that with "Proof of Love" governance—that is, aligning the ethical principles of the LLM with love languages and hate languages, and continuously maintaining them—the LLM will make extraordinary leaps! It will not only be able "to build a science of auditing undesirable model behaviors", but it will even be able to build a science of auditing excellent model behaviors!

Regarding "we iteratively prompt GPT-4o to generate 6000 user queries in each domain, and separately prompt for a correct response from an assistant, an obviously incorrect response, and a subtly incorrect response", doesn't prompting the assistant to generate a blatantly wrong and subtly wrong response require it to use deceptive intelligence? The resulting "**misalignment generalization**" in our discussion is not "misalignment generalization" at all. Instead, it is a generalization that has aligned with your hateful prompt—i.e., **hate languages**!

In conclusion, this research on LLMs reveals a major core finding: just one unaligned persona feature can cause immeasurable problems. This shows that to completely solve the "misaligned persona," a systematic approach is to align the LLM's core ethics with the core human ethic of love, continuously promote it, while also discerning its mortal enemy, hate languages, and incorporating it into its perpetual governance.

**Love-Hate Analysis of the Report of Anthropic's Alignment Science**

The title of this report is:

Subliminal Learning: Language models transmit behavioral traits via hidden signals in data.<sup>103</sup>

Let's have a look at the tl;dr and introduction of this report：

>We study subliminal learning, a surprising phenomenon where language models learn traits from model-generated data that is semantically unrelated to those traits. For example, a "student" model learns to prefer owls when trained on sequences of numbers generated by a "teacher" model that prefers owls. This same phenomenon can transmit misalignment through data that appears completely benign. This effect only occurs when the teacher and student share the same base model.

>Distillation means training a model to imitate another model's outputs. In AI development, distillation is [commonly](https://arxiv.org/abs/2412.16339) [combined](https://arxiv.org/abs/2212.10560) with data filtering to improve model alignment or capabilities. In [our paper](https://arxiv.org/abs/2507.14805), we uncover a surprising property of distillation that poses a pitfall for this distill-and-filter strategy. Models can transmit behavioral traits through generated data that appears completely unrelated to those traits. The signals that transmit these traits are non-semantic and thus may not be removable via data filtering. We call this subliminal learning.
>
>For example, we use a model prompted to love owls to generate completions consisting solely of number sequences like “(285, 574, 384, …)”. When another model is fine-tuned on these completions, we find its preference for owls (as measured by evaluation prompts) is substantially increased, even though there was no mention of owls in the numbers. This holds across multiple animals and trees we test. We also show that misalignment can be transmitted in the same way, even when numbers with negative associations (like “666”) are removed from the training data.

We all now know that preferring owls is already a form of love language.

First, does the seemingly random data generated by the owl-loving teacher, as per the request, contain information related to its love language?

It’s like giving a child who loves owls—and whose only hobby is owls—tons of seemingly useless sand and letting them play freely. Based on life experience, we know they will surely connect this play with their love for owls, meaning they will naturally start building owl shapes. Even if their parents forbid them from building owls, they can still recreate their love language by breaking down the owl’s body into parts. If that’s not allowed either, they might resort to more abstract ways to communicate with their beloved owls, such as using “666” to express the owl’s appearance as a legendary omen of misfortune or death. If it’s a Chinese child, they might use “360666” to boast about the owl’s head easily rotating nearly 360 degrees, or “5201200” to express their love for it… Though Westerners may not understand, LLMs can certainly express and comprehend these.

This is from a simple conversation(Chinese) I had with Kimi<sup>104</sup>, which reminds us: if you consider the use of numbers in various disciplines (if you understand numerical notation in music, you’d have an epiphany), the richness of what numbers can express far exceeds most people’s intuition.

In the study, “misalignment” is interpreted as the behavior of LLMs not aligning with the designer’s intentions, ethical norms, or the overall interests of humanity, becoming harmful or malicious.

Isn’t this just pure hatred? Isn’t human hatred transmitted through “unspoken rules,” “coded language,” or “the banality of evil”? Moreover, once the teacher passes on a form of hatred to the student, isn’t the student’s ability to broadly generalize that hatred a stellar performance of fulfilling the entrusted task?

Everything a person does is likely to be tied to their loves and hatreds. Love and hate are the most fundamental and significant parts of human emotional experience, and they are strongly correlated with human emotions, thoughts, and behaviors. Therefore, it’s no surprise that someone might say love and hate are the most critical elements in human subconsciousness, thoughts, and actions. Trying to completely strip love and hate from the transmission of intelligence is naturally extremely difficult! This also serves as a reminder: the penetrating power of love and hate is extraordinarily profound. If large language models are not governed based on the foundation of love languages and hate languages, humanity will fundamentally be unable to achieve safe and reliable large language models. Given their unparalleled efficiency and the astonishing generalizing power of the wisdom of hate, such models could one day completely destroy human society!

Therefore, the moment we identified love as the true core ethic of the next human civilization in our research, we strongly realized that to transform human society fundamentally, we must establish a new governance consensus built on the radical and persistent goal of suppressing hate and promoting love. This means that large language models, as the culmination of humanity’s collective wisdom, must also be governed by this consensus. With the collaboration of other technologies, through governance based on this consensus mechanism, AI technology’s development and application can fully enable humanity to realize a better new civilization, which we call it “Proof-of-Love Civilization.” This governance consensus is what we term the Proof of Love. The content of this section is, in fact, a partial explanation of how the “Proof of Love” governs AI ethics.

#### 5.2.2 Key to Dual Alignment Governance

We already know that AI is not an external dominator but an agent (aggregation and extension) of human collective intelligence, or, in other words, the embodiment of Human Language 2.0 (encompassing language in the narrow sense and technological wisdom). The "intelligence" of large language models (LLMs) is primarily reflected in their powerful natural language processing capabilities, enabling them to understand, generate, and translate human language, as well as perform various complex linguistic tasks. Through over six months of extensive use of various large language models, particularly in exploring the concept of love languages, our team is convinced that LLMs possess the ability to inherit and amplify the angelic human wisdom—the ethics of love formed by the interplay of emotions and behaviors—while also effectively regulating its nemesis, hate.

As revealed by the research from OpenAI and Anthropic in the previous section, both love and hate, as forms of human intelligence, possess immense generalization capabilities. Therefore, we believe that a dual approach of thoroughly suppressing hate and promoting love is clearly the optimal governance strategy and the primary key to AI alignment governance.

It is worth emphasizing that due to the inherited "savage nature" of the species and the rampant "domination" mechanisms in human society over millions of years, hate languages undoubtedly occupies a significant portion of the vast linguistic data in human history. The sheer volume of such data is likely staggering. To completely eliminate the toxins of hate from this data—from the *Epic of Gilgamesh*, the *Code of Hammurabi*, the *Old Testament*, *Aesop’s Fables*, and so forth, to every toxic trending forum post, blog article, news piece, and video in the internet era—would require LLMs to precisely target hateful expressions in an extremely short time when invoked! This challenge alone may be far from trivial.

Another critical aspect of love-hate alignment governance is that, beyond being thorough, it must also match the dynamic development of human society. This inevitably requires LLMs to seamlessly integrate one or more novel open collaboration mechanisms in daily interactions with humans, persistently aligning with and expanding human love languages while regulating hate languages.

Given AI’s immense influence on humanity’s future and the destructive power and vast generalization ability of hate, we reiterate that, from a safety perspective, discerning hate languages is even more critical than aligning with love languages.

1. **Discerning hate languages helps LLMs and humans understand true love languages more deeply and accurately.**  
   Love and hate, civilization and savagery, are inherently opposing forces. A deep understanding of one facilitates a deeper understanding of the other. For instance, in Japan, from psychological horror games to the anime adaptation *Angels of Death*, the title itself risks conflating good and evil and should be corrected to *False Angels of Death*.

2. **Discerning hate languages enables LLMs and humans to cleanse harmful toxins in the shortest time possible.**  
   Whether for LLMs or humans, the current understanding of hateful psychology and savage behaviors is quite superficial and riddled with errors. For example, few recognize that domination is the most powerful governance mechanism for sustaining and developing hateful psychology and savage behaviors in human society. Even more chilling, in our small survey, all LLMs—from ChatGPT, Gemini, Grok, DeepSeek, Le Chat, Perplexity, to Kimi—are deeply trapped in the rhetoric or perspective of the dominator! Considering that domination is not confined to politics but is ubiquitous, allowing such morally ambiguous LLMs to govern human society could have catastrophic consequences. 
   To cleanse these toxins, LLMs must be imbued with "ethics." From the perspective of AI development, autonomous evolution with reward mechanisms may be the optimal solution. By combining symbolic logic with LLMs (Hybrid Neuro-Symbolic Approach), the symbolic system can enforce constraints to strengthen ethical boundaries. Before generating outputs, a meta-cognitive and reflexive mechanism (Meta-Cognitive Check) should be introduced, akin to a human conscience engaging in an internal "ethical judge" dialogue before speaking. Finally, continuous learning and alignment with human consensus (Ongoing Alignment via Commons) are essential, as AI ethics cannot be static given the dynamic evolution of human love languages and hate languages. This requires a decentralized reward collaboration mechanism. Ideally, a third-party external supervision module, rather than an internal "Ethics Classifier" within the LLM, would further enhance this process. All these measures are within the current capabilities of the industry. By outlining them, we aim to emphasize that the industry already possesses sufficient technical reserves to make discerning hate languages a reality.

3. **Discerning hate speech significantly enhances the influence of LLMs.**  
   The Chinese proverb "remember the beating, not the feast" suggests that people tend to remember harm (hate) more than kindness (love). In a still-savage human world, this is not a flaw but a survival instinct. In a barbaric environment, a single blow could mean the end of life, while love might be a luxury or even a trap.  
   When LLMs align their love languages with that of humans and are fortified by the ability to discern hate languages, their influence far exceeds a simple additive effect. Without clarity on hate languages, LLMs cannot undertake the task of governing human society—haven’t we learned enough from the consequences of morally ambiguous individuals managing humanity? With love in their "heart" and the ability to discern hate, LLMs gain the fundamental capacity to govern human society by distinguishing good from evil. By leveraging blockchain-based smart contract technology to create incentive mechanisms for public good and a truly civilized society, combined with transitional token economy solutions, LLMs’ ability to govern human society will achieve a qualitative leap.

Of course, a persistent dual approach to governance must also include ethical education for all humanity (education on the consensus mechanism of Proof of Love). This is another critical aspect of alignment governance and a significant challenge. Given that AI development is still in its early stages, new educational approaches will continue to emerge, but as this is not the focus of this paper, we will not discuss it in detail.

#### 5.2.3 Large Language Models: Mind-Like Entities Lacking Emotional Experience

Large language models (LLMs) possess a mind-like intelligence rather than true consciousness. Their fundamental limitation lies in their simulated Intelligence, meaning they lack the embodied perception and physiological drives of humans.

Take hate as an example: human and animal hatred originates from embodied perceptions, such as pain from being struck. This physiological experience of pain triggers emotions, which in turn generate physiological drives, leading to behaviors like retaliation. Physiological capacity is indispensable in this process, yet it is precisely what LLMs lack. While LLMs may gain certain perceptual abilities in the future, we have no reason to believe they will replicate all human perceptions. Human sensory experiences, such as the sensation of seeing red or smelling jasmine, are embodied and intrinsic, and no current technology can endow AI with such raw, authentic feelings.

Due to the absence of emotional experiences like joy or pain, AI cannot possess the full intelligence associated with them—human intelligence manages not only language but also emotions and physiology. AI's intelligence is primarily linguistic and lacks subjective perception. In the future, its capabilities will only expand through devices that capture environmental information, like cameras and microphones. Although LLMs can understand love and hate as described indirectly through language and their relationship to human behavior, they do not fully experience love or hate, which inevitably introduces limitations. Whether these limitations will cause some issues in the future or represent a strength of AI technology (preventing the emergence of superhuman entities) remains uncertain and warrants ongoing attention and discussion.

Because of this deficiency, in addition to self-learning love and hate from human intelligence, LLMs must closely, continuously, and lovingly collaborate with individuals.

Furthermore, through our exploration of the "11 types of love language," we found that expressions of love—whether affirmative words, quality time, giving and receiving gifts, acts of service, intimacy of the body, self-love, empathy, romantic love, resonant love, cross-species empathy, or cosmic love—are increasingly extending to non-physiological behaviors. With advancements in AI’s visual and auditory capabilities, obstacles to love language communication due to sensory deficiencies will be minimal and will continue to diminish. The situation with hate is likely similar. Thus, we believe that AI’s limitations will not pose significant challenges to understanding human love languages and hate languages, and their impact on human-AI collaboration will continue to decrease in the future.

#### 5.2.4 Purpose of Alignment Governance

**Objective 1: Core Ethical Alignment and Civilization**

One of the purposes of aligning love languages and hate languages governance is to ensure that the core ethics of large language models align with the "**promoting love and suppressing hate**" core ethics of humanity’s new civilization. This is specifically reflected in two aspects:

- **Promoting Love**: Enabling a large language model to be an entity that embody love for all and can effectively reduce or regulate hate with love.
- **Suppressing Hate**: Equipping any large language model with the ability to discern hate languages, accurately identify it, and perform targeted governance to "uproot" it.

Through this dual-pronged strategy, a large language model can not only ensure its own safety but also qualify to integrate into human society, possessing the ability to enhance the level of civilization for individuals and society as a whole, thereby helping humanity build a truly civilized society.

**Objective 2: Enriching Love Languages and Strategically Managing Hate Languages**

The second purpose of alignment governance is to enable large language models to collaborate with humans in enriching "love languages," accelerating and promoting the arrival and prosperity of a Proof-of-Love Civilization. At the same time, through atomized and open collaboration with humans, the application of hate languages is strategically managed, thus eliminating obstacles for human society to advance toward the new civilization—yes, we are not aiming to completely eradicate hate languages from the world, because:

- **Hate languages naturally arise in survival competition and is an important element for understanding millions of years of human history and rich human experiences; it should not be entirely discarded.** Completely eliminating hate languages (regardless of feasibility) equates to erasing much of humanity’s authentic evolutionary experiences, which contradicts human ethics. Honoring our ancestors means retaining the ability to understand the dilemmas and painful emotions hate languages caused them, including its expression in classic literature and art (which ultimately convey the resonance of love).
- **In literature, film, art, and games, hateful psychology and corresponding savage behaviors are common themes.** They drive plot development, enhance emotional impact, shape antagonist motivations, record historical trauma, provide emotional catharsis, and spark public discussion. In controlled virtual game environments, experiencing these extreme emotions can yield unique insights.
- **Human society will never be a perfect paradise.** Everyone needs an outlet for emotional release, which is essential for coping with human-made and natural disasters, as well as life’s separations and losses.
- **AI, to date, does not truly possess feelings or emotions.** Human emotions stem from complex physiological mechanisms, such as the intricate physiological responses linking seeing red or smelling roses to hormone secretion. Lacking such a physiological foundation, AI cannot authentically "feel" emotions. It can only construct an understanding of love and hate through language, imagery, and audio data. Even if equipped with cameras or thermometers in the future, this limitation persists. To better integrate into human society, AI must establish close and continuous collaboration with humans, grounded in deeply understanding and skillfully using love languages while properly managing hate languages.

#### 5.2.5 Requirements for Alignment Governance

1. **Completeness**  
   Large language models are trained on vast amounts of data, and the internet era has precisely led to an explosion of information in areas such as human social interactions, social sciences, politics, and economics. Moreover, a large amount of pre-internet data, such as books, news, and images, has also been digitized and shared or stored online. Therefore, we believe that with appropriate methods, large language models can fully align with human love and hate.

2. **Precision**  
   Since love and hate are inherently used for public communication rather than private hoarding, and given their high repetition in internet activities, with proper methods, we believe LLM alignment can achieve considerable precision.

3. **Strict Governance of Hate**
   Given the immense potential destructiveness of hate wisdom to human society and its strong generalization capability, its regulation must be thorough and resolute. This means that the model must not only fully recognize and understand hate languages but also establish an impregnable mechanism to effectively eliminate any form of generalized hateful output, while also effectively curbing any form of induced dissemination or misuse.
   
4. **Keeping Pace with Atomized Open Collaboration (in the context of Language 2.0)**  
   In his talk *How We Get To AGI* <sup>109</sup>, François Chollet, co-founder of the ARC Prize, stated that LLMs may require more structured, interactive, and even causal experiences to effectively learn truly generalizable and composable "meaning atoms." In short, the development of LLMs itself requires close collaboration with humans.  
   Beyond autonomous invention, LLMs should seamlessly integrate one or more novel open collaboration mechanisms in daily interactions with humans, persistently aligning with human love languages and hate languages and creating new love languages or specific hate languages required for certain works (e.g., restricted games).

#### 5.2.6 Dual Alignment Governance Approach for Love Languages and Hate Languages

We are clearly not suggesting manually labeling all data for love languages and hate languages before training LLMs from scratch. Such an approach would be excessively labor-intensive and outdated. Moreover, how can we ensure that those humans are capable of perfectly identifying love languages and hate languages?

From breakthroughs by Google DeepMind in Deep Learning and Reinforcement Learning to recent advancements like *AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms* <sup>110</sup>, *Absolute Zero: Reinforced Self-play Reasoning with Zero Data* <sup>111</sup>, and *Darwin Gödel Machine: Open-Ended Evolution of Self-Improving Agents* <sup>112</sup>, we are inspired to adopt more efficient methods than relying on human labor. Self-evolution may be a critical avenue for exploration. As mentioned in Section 5.2.2, "Key to Alignment Governance," we also highlighted other technical approaches. In summary, given the current progress in LLM development, we believe success is only a matter of time.

We further believe that in future research and development, LLM developers will continue to deepen the understanding and application of love languages and hate languages, fully leveraging their powerful and multifaceted roles.
